{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch_geometric_temporal.dataset import METRLADatasetLoader\n",
    "from torch_geometric_temporal.signal import StaticGraphTemporalSignal\n",
    "import os\n",
    "import urllib\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.utils import dense_to_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoader(object):\n",
    "    \"\"\"A traffic forecasting dataset based on Los Angeles\n",
    "    Metropolitan traffic conditions. The dataset contains traffic\n",
    "    readings collected from 207 loop detectors on highways in Los Angeles\n",
    "    County in aggregated 5 minute intervals for 4 months between March 2012\n",
    "    to June 2012.\n",
    "\n",
    "    For further details on the version of the sensor network and\n",
    "    discretization see: `\"Diffusion Convolutional Recurrent Neural Network:\n",
    "    Data-Driven Traffic Forecasting\" <https://arxiv.org/abs/1707.01926>`_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, raw_data_dir=os.path.join(os.getcwd(), \"data\")):\n",
    "        super(CustomLoader, self).__init__()\n",
    "        self.raw_data_dir = raw_data_dir\n",
    "        self._read_web_data()\n",
    "\n",
    "    def _download_url(self, url, save_path):  # pragma: no cover\n",
    "        with urllib.request.urlopen(url) as dl_file:\n",
    "            with open(save_path, \"wb\") as out_file:\n",
    "                out_file.write(dl_file.read())\n",
    "\n",
    "    def _read_web_data(self):\n",
    "        url = \"https://graphmining.ai/temporal_datasets/METR-LA.zip\"\n",
    "\n",
    "        # Check if zip file is in data folder from working directory, otherwise download\n",
    "        if not os.path.isfile(\n",
    "            os.path.join(self.raw_data_dir, \"METR-LA.zip\")\n",
    "        ):  # pragma: no cover\n",
    "            if not os.path.exists(self.raw_data_dir):\n",
    "                os.makedirs(self.raw_data_dir)\n",
    "            self._download_url(url, os.path.join(self.raw_data_dir, \"METR-LA.zip\"))\n",
    "\n",
    "        if not os.path.isfile(\n",
    "            os.path.join(self.raw_data_dir, \"adj_mat.npy\")\n",
    "        ) or not os.path.isfile(\n",
    "            os.path.join(self.raw_data_dir, \"node_values.npy\")\n",
    "        ):  # pragma: no cover\n",
    "            with zipfile.ZipFile(\n",
    "                os.path.join(self.raw_data_dir, \"METR-LA.zip\"), \"r\"\n",
    "            ) as zip_fh:\n",
    "                zip_fh.extractall(self.raw_data_dir)\n",
    "\n",
    "        A = np.load(os.path.join(self.raw_data_dir, \"adj_mat.npy\"))\n",
    "        X = np.load(os.path.join(self.raw_data_dir, \"node_values.npy\")).transpose(\n",
    "            (1, 2, 0)\n",
    "        )\n",
    "        X = X.astype(np.float32)\n",
    "\n",
    "        # Normalise as in DCRNN paper (via Z-Score Method)\n",
    "        means = np.mean(X, axis=(0, 2))\n",
    "        X = X - means.reshape(1, -1, 1)\n",
    "        stds = np.std(X, axis=(0, 2))\n",
    "        X = X / stds.reshape(1, -1, 1)\n",
    "\n",
    "        self.A = torch.from_numpy(A)\n",
    "        self.X = torch.from_numpy(X)\n",
    "\n",
    "    def _get_edges_and_weights(self):\n",
    "        edge_indices, values = dense_to_sparse(self.A)\n",
    "        edge_indices = edge_indices.numpy()\n",
    "        values = values.numpy()\n",
    "        self.edges = edge_indices\n",
    "        self.edge_weights = values\n",
    "\n",
    "    def _generate_task(self, num_timesteps_in: int = 12, num_timesteps_out: int = 12):\n",
    "        \"\"\"Uses the node features of the graph and generates a feature/target\n",
    "        relationship of the shape\n",
    "        (num_nodes, num_node_features, num_timesteps_in) -> (num_nodes, num_timesteps_out)\n",
    "        predicting the average traffic speed using num_timesteps_in to predict the\n",
    "        traffic conditions in the next num_timesteps_out\n",
    "\n",
    "        Args:\n",
    "            num_timesteps_in (int): number of timesteps the sequence model sees\n",
    "            num_timesteps_out (int): number of timesteps the sequence model has to predict\n",
    "        \"\"\"\n",
    "        indices = [\n",
    "            (i, i + (num_timesteps_in + num_timesteps_out))\n",
    "            for i in range(self.X.shape[2] - (num_timesteps_in + num_timesteps_out) + 1)\n",
    "        ]\n",
    "\n",
    "        # Generate observations\n",
    "        features, target = [], []\n",
    "        for i, j in indices:\n",
    "            features.append((self.X[:, :, i : i + num_timesteps_in]).numpy())\n",
    "            target.append((self.X[:, 0, i + num_timesteps_in : j]).numpy())\n",
    "\n",
    "        self.features = features\n",
    "        self.targets = target\n",
    "\n",
    "    def get_dataset(\n",
    "        self, num_timesteps_in: int = 12, num_timesteps_out: int = 12\n",
    "    ) -> StaticGraphTemporalSignal:\n",
    "        \"\"\"Returns data iterator for METR-LA dataset as an instance of the\n",
    "        static graph temporal signal class.\n",
    "\n",
    "        Return types:\n",
    "            * **dataset** *(StaticGraphTemporalSignal)* - The METR-LA traffic\n",
    "                forecasting dataset.\n",
    "        \"\"\"\n",
    "        self._get_edges_and_weights()\n",
    "        self._generate_task(num_timesteps_in, num_timesteps_out)\n",
    "        dataset = StaticGraphTemporalSignal(\n",
    "            self.edges, self.edge_weights, self.features, self.targets\n",
    "        )\n",
    "\n",
    "        return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from IPython.display import clear_output\n",
    "pt_version = torch.__version__\n",
    "print(pt_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type:   <torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal object at 0x7fc3390f8a00>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "loader = CustomLoader()\n",
    "dataset = loader.get_dataset(num_timesteps_in=12, num_timesteps_out=12)\n",
    "\n",
    "print(\"Dataset type:  \", dataset)\n",
    "#print(\"Number of samples / sequences: \",  len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[207, 2, 12], edge_index=[2, 1722], edge_attr=[1722], y=[207, 12])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34249"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(iter(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[207, 2, 12], edge_index=[2, 1722], edge_attr=[1722], y=[207, 12])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train buckets:  27399\n",
      "Number of test buckets:  6850\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n",
    "\n",
    "print(\"Number of train buckets: \", len(list(iter((train_dataset)))))\n",
    "print(\"Number of test buckets: \", len(list(iter((test_dataset)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TemporalGNN(\n",
       "  (tgnn): A3TGCN(\n",
       "    (_base_tgcn): TGCN(\n",
       "      (conv_z): GCNConv(2, 32)\n",
       "      (linear_z): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (conv_r): GCNConv(2, 32)\n",
       "      (linear_r): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (conv_h): GCNConv(2, 32)\n",
       "      (linear_h): Linear(in_features=64, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=32, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import A3TGCN\n",
    "\n",
    "class TemporalGNN(torch.nn.Module):\n",
    "    def __init__(self, node_features, periods):\n",
    "        super(TemporalGNN, self).__init__()\n",
    "        # Attention Temporal Graph Convolutional Cell\n",
    "        self.tgnn = A3TGCN(in_channels=node_features, \n",
    "                           out_channels=32, \n",
    "                           periods=periods)\n",
    "        # Equals single-shot prediction\n",
    "        self.linear = torch.nn.Linear(32, periods)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        x = Node features for T time steps\n",
    "        edge_index = Graph edge indices\n",
    "        \"\"\"\n",
    "        h = self.tgnn(x, edge_index)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear(h)\n",
    "        return h\n",
    "\n",
    "TemporalGNN(node_features=2, periods=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [02:12<04:25, 132.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train MSE: 0.7606\n"
     ]
    }
   ],
   "source": [
    "# GPU support\n",
    "from tqdm import tqdm\n",
    "device = torch.device('cpu') # cuda\n",
    "subset = 2000\n",
    "\n",
    "# Create model and optimizers\n",
    "model = TemporalGNN(node_features=2, periods=12).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "model.train()\n",
    "\n",
    "print(\"Running training...\")\n",
    "for epoch in tqdm(range(3)): \n",
    "    loss = 0\n",
    "    step = 0\n",
    "    for snapshot in train_dataset:\n",
    "        snapshot = snapshot.to(device)\n",
    "        # Get model predictions\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index)\n",
    "        # Mean squared error\n",
    "        loss = loss + torch.mean((y_hat-snapshot.y)**2) \n",
    "        step += 1\n",
    "        if step > subset:\n",
    "            break\n",
    "\n",
    "    loss = loss / (step + 1)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    print(\"Epoch {} train MSE: {:.4f}\".format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "loss = 0\n",
    "step = 0\n",
    "horizon = 288\n",
    "\n",
    "# Store for analysis\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for snapshot in test_dataset:\n",
    "    snapshot = snapshot.to(device)\n",
    "    # Get predictions\n",
    "    y_hat = model(snapshot.x, snapshot.edge_index)\n",
    "    # Mean squared error\n",
    "    loss = loss + torch.mean((y_hat-snapshot.y)**2)\n",
    "    # Store for analysis below\n",
    "    labels.append(snapshot.y)\n",
    "    predictions.append(y_hat)\n",
    "    step += 1\n",
    "    if step > horizon:\n",
    "          break\n",
    "\n",
    "loss = loss / (step+1)\n",
    "loss = loss.item()\n",
    "print(\"Test MSE: {:.4f}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sensor = 123\n",
    "timestep = 11 \n",
    "preds = np.asarray([pred[sensor][timestep].detach().cpu().numpy() for pred in predictions])\n",
    "labs  = np.asarray([label[sensor][timestep].cpu().numpy() for label in labels])\n",
    "print(\"Data points:,\", preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.figure(figsize=(20,5))\n",
    "sns.lineplot(data=preds, label=\"pred\")\n",
    "sns.lineplot(data=labs, label=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c8154bc89338aa61183803fddff66c28cb5c44ca94b859a7dd1cc91d2b6a781"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
